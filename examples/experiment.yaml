# SWE-Bench Plugin Efficiency Benchmark Configuration
# Example: Plugin Ablation Study
#
# This configuration compares three plugin configurations:
# 1. Baseline - No tools (pure LLM)
# 2. File Tools - Basic file operations only
# 3. Full Stack - All available tools
#
# Usage:
#   swe-bench-harness --config examples/experiment.yaml
#   swe-bench-harness --config examples/experiment.yaml --dry-run

name: "plugin-ablation-study"

# Dataset configuration
dataset:
  # HuggingFace dataset source
  source: "princeton-nlp/SWE-bench_Lite"

  # Dataset split with optional slicing
  # Examples:
  #   - "test[:10]"  - First 10 instances
  #   - "test[10:20]" - Instances 10-19
  #   - "test[:10%]" - First 10%
  split: "test[:10]"

  # Random seed for reproducibility
  seed: 42

  # Local cache directory
  cache_dir: "~/.cache/swe-bench"

# Execution parameters
execution:
  # Number of repeated runs per instance for variance analysis
  runs_per_instance: 3

  # Maximum concurrent benchmark executions
  max_parallel_tasks: 2

  # Timeout in seconds for each run (default: 15 minutes)
  timeout_per_run_sec: 600

# Claude model configuration
# Note: max_tokens and temperature are controlled by Claude Code CLI defaults
# and cannot be configured through the SDK
model:
  # Model identifier
  name: "claude-sonnet-4-5"

# Plugin configurations to compare
# Each configuration runs against all instances
configs:
  # Baseline: Pure LLM without any tools
  - id: "baseline"
    name: "Baseline (No Tools)"
    description: "Pure LLM without external tools - measures base capability"
    allowed_tools: []

  # File Tools: Basic file operations only
  - id: "file_tools"
    name: "File Operations Only"
    description: "Read/write/list file tools enabled"
    allowed_tools:
      - "read_file"
      - "write_file"
      - "list_directory"

  # Full Stack: All tools enabled
  - id: "full_stack"
    name: "Full Tool Stack"
    description: "All available tools enabled"
    allowed_tools:
      - "*"  # Wildcard for all tools

# Token pricing for cost estimation
pricing:
  # Cost in USD per million input tokens
  input_cost_per_mtok: 3.0

  # Cost in USD per million output tokens
  output_cost_per_mtok: 15.0

  # Cost in USD per million cache read tokens
  cache_read_cost_per_mtok: 0.30

# Output directory for results
output_dir: "./results/ablation-study"
